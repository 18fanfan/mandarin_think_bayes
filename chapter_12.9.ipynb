{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 章節 12：證據\n",
    "\n",
    "## 12.9 討論\n",
    "\n",
    "這章節我們從一個問題開始，「證據有多支持 Alice 準備的比 Bob 好？」從表面上來看，似乎我們想要測試兩個假設：Alice 準備的比 Bob 好或是相反。\n",
    "\n",
    "但為了計算兩個假設的似然性，我們要解決一個評估的問題。對每一個測試者我們需要計算 p_correct 和功率的後驗分佈。像這想個值我們稱為討厭的參數，因為我們不在意他們，但我們必須估計他們來得到我們在意的答案。\n",
    "\n",
    "可視化我們在本章中進行的分析的一種方法是繪製這些參數的空間。thinkbayes.MakeJoint 方法需要兩個 pmf 物件計算他們的聯合分佈，並且回傳聯合分佈的 pmf。\n",
    "\n",
    "<pre>\n",
    "def MakeJoint(pmf1, pmf2):\n",
    "    joint = Joint()\n",
    "    for v1, p1 in pmf1.Items():\n",
    "        for v2, p2 in pmf2.Items():\n",
    "            joint.Set((v1, v2), p1 * p2)\n",
    "    return joint\n",
    "</pre>\n",
    "\n",
    "以上假設兩個分佈是獨立的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上圖為 Alice 和 Bob 的 p_correct 分佈的聯合分佈。對角線為 Alice 和 Bob 的 p_correct 一樣的機率。此線的右邊表示 Alice 準備較好；左邊為 Bob 準備較好。\n",
    "\n",
    "TopLevel.Update 方法計算 Alice 和 Bob 的似然性，我們加總在線兩邊所有的機率。而在線上的格子，我們平均分配在 Alice 和 Bob。\n",
    "\n",
    "本章中使用的過程 - 估計煩擾參數以評估競爭假設的可能性 - 就是將於貝葉斯方法用於此類問題上常見的流程。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
